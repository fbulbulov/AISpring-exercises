{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from requests import get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J.K. Rowling\n"
     ]
    }
   ],
   "source": [
    "def get_hundred_book_links():\n",
    "    page = requests.get(url=\"https://www.goodreads.com/list/show/1.Best_Books_Ever?page=1\")\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    links_section = soup.find_all('a', class_=\"bookTitle\", href=True)\n",
    "    final_links = [\"https://www.goodreads.com\" + link['href'] for link in links_section]\n",
    "    return final_links\n",
    "\n",
    "\n",
    "get_hundred_book_links()\n",
    "\n",
    "\n",
    "### Individual page\n",
    "def get_author(page_url):\n",
    "    request = requests.get(page_url)\n",
    "    page_soup = BeautifulSoup(request.content, 'html.parser')\n",
    "    author_section = page_soup.find('a', class_=\"authorName\").get_text()\n",
    "    return author_section\n",
    "\n",
    "test = get_author(\"https://www.goodreads.com/book/show/2.Harry_Potter_and_the_Order_of_the_Phoenix\")\n",
    "\n",
    "print(test)\n",
    "def main(page_url):\n",
    "    author = get_author()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45345\n"
     ]
    }
   ],
   "source": [
    "def get_num_reviews(page_url):\n",
    "    request=requests.get(page_url)\n",
    "    page_soup=BeautifulSoup(request.content,'html.parser')\n",
    "    get_num_unclean=page_soup.find('meta',itemprop=\"reviewCount\")\n",
    "    get_num_reviews=int(get_num_unclean['content'])\n",
    "    return get_num_reviews\n",
    "test2=get_num_reviews(\"https://www.goodreads.com/book/show/2.Harry_Potter_and_the_Order_of_the_Phoenix\")\n",
    "print(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average rate\n",
    "def get_avg(page_url):\n",
    "    request=requests.get(page_url)\n",
    "    page_soup=BeautifulSoup(request.content,'html.parser')\n",
    "    \n",
    "    get_avg=float(page_soup.find('span',itemprop=\"ratingValue\").get_text())\n",
    "    return get_avg\n",
    "\n",
    "test3=get_avg(\"https://www.goodreads.com/book/show/2.Harry_Potter_and_the_Order_of_the_Phoenix\")\n",
    "\n",
    "print(test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute 'get_text'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-fcb6bad21d7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mget_place\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpage_soup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'a[href*=\"/places\"]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mget_place\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtest5\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_place\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"https://www.goodreads.com/book/show/2.Harry_Potter_and_the_Order_of_the_Phoenix\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-62-fcb6bad21d7e>\u001b[0m in \u001b[0;36mget_place\u001b[1;34m(page_url)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mpage_soup\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mget_place\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpage_soup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'a[href*=\"/places\"]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mget_place\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtest5\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_place\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"https://www.goodreads.com/book/show/2.Harry_Potter_and_the_Order_of_the_Phoenix\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2171\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2172\u001b[0m         \u001b[1;34m\"\"\"Raise a helpful exception to explain a common code fix.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2173\u001b[1;33m         raise AttributeError(\n\u001b[0m\u001b[0;32m   2174\u001b[0m             \u001b[1;34m\"ResultSet object has no attribute '%s'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2175\u001b[0m         )\n",
      "\u001b[1;31mAttributeError\u001b[0m: ResultSet object has no attribute 'get_text'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "# Place (setting)\n",
    "def get_place(page_url):\n",
    "    request=requests.get(page_url)\n",
    "    page_soup=BeautifulSoup(request.content,'html.parser')\n",
    "    get_place=page_soup.select('a[href*=\"/places\"]').get_text()\n",
    "    return get_place\n",
    "test5=get_place(\"https://www.goodreads.com/book/show/2.Harry_Potter_and_the_Order_of_the_Phoenix\")\n",
    "\n",
    "print(test5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hogwarts School of Witchcraft and Wizardry, London, England\n"
     ]
    }
   ],
   "source": [
    "def get_place(page_url):\n",
    "    request=requests.get(page_url)\n",
    "    page_soup=BeautifulSoup(request.content,'html.parser')\n",
    "    get_place=page_soup.select('a[href*=\"/places\"]')\n",
    "    place=[]\n",
    "    for x in get_place:\n",
    "        place.append(x.get_text())\n",
    "    return (\", \".join(place))\n",
    "      \n",
    "      \n",
    "test5=get_place(\"https://www.goodreads.com/book/show/2.Harry_Potter_and_the_Order_of_the_Phoenix\")\n",
    "print(test5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bram Stoker Award for Works for Young Readers (2003), Anthony Award for Young Adult (2004), Mythopoeic Fantasy Award for Children's Literature (2008), Audie Award for Audiobook of the Year (2004), Books I Loved Best Yearly (BILBY) Awards for Older Readers (2004), Colorado Blue Spruce Young Adult Book Award (2006), Golden Archer Award for Middle/Junior High (2005), Deutscher Jugendliteraturpreis Nominee for Preis der Jugendjury (2004), Carnegie Medal Nominee (2003)\n"
     ]
    }
   ],
   "source": [
    "def get_awards(page_soup):\n",
    "    request=requests.get(page_soup)\n",
    "    page_soup=BeautifulSoup(request.content,'html.parser')\n",
    "    try:\n",
    "        awards_section = page_soup.find('div', itemprop=\"awards\")\n",
    "        awards = awards_section.find_all('a', class_=\"award\")\n",
    "        main_awards = [award.get_text().strip() for award in awards]\n",
    "        str_main_awards = \", \".join(main_awards)\n",
    "        return str_main_awards\n",
    "    except:\n",
    "        print(\"Oh no get_awards failed\")\n",
    "        return np.nan\n",
    "test=get_awards(\"https://www.goodreads.com/book/show/2.Harry_Potter_and_the_Order_of_the_Phoenix\")\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "def get_awards(page_soup):\n",
    "    request=requests.get(page_soup)\n",
    "    page_soup=BeautifulSoup(request.content,'html.parser')\n",
    "    try:\n",
    "        awards_section = page_soup.find('div', itemprop=\"awards\")\n",
    "        awards = awards_section.find_all('a', class_=\"award\")\n",
    "        main_awards = [award.get_text().strip() for award in awards]\n",
    "        str_main_awards =len((\", \".join(main_awards)).split(','))\n",
    "        return str_main_awards\n",
    "    except:\n",
    "        print(\"Oh no get_awards failed\")\n",
    "        return np.nan\n",
    "test=get_awards(\"https://www.goodreads.com/book/show/2.Harry_Potter_and_the_Order_of_the_Phoenix\")\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "def get_awards_count(page_soup):\n",
    "    request=requests.get(page_soup)\n",
    "    page_soup=BeautifulSoup(request.content,'html.parser')\n",
    "    try:\n",
    "        awards_section = page_soup.find('div', itemprop=\"awards\")\n",
    "        awards = awards_section.find_all('a', class_=\"award\")\n",
    "        main_awards = [award.get_text().strip() for award in awards]\n",
    "        str_main_awards =len((\", \".join(main_awards)).split(','))\n",
    "        return str_main_awards\n",
    "    except:\n",
    "        print(\"Oh no get_awards failed\")\n",
    "        return np.nan\n",
    "test=get_awards(\"https://www.goodreads.com/book/show/7260188-mockingjay\")\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all(list_of_urls):\n",
    "    pd_data =[]\n",
    "    for book_url in list_of_urls:\n",
    "        print(f\"Working on url: {book_url}\")\n",
    "        request = requests.get(book_url)\n",
    "        page_soup = BeautifulSoup(request.content,'html.parser')\n",
    "        title = get_title(page_soup)\n",
    "        author = get_author(page_soup)\n",
    "        num_reviews = get_num_reviews(page_soup)\n",
    "        num_ratings = get_number_of_ratings(page_soup)\n",
    "        avg_rating = get_avg(page_soup)\n",
    "        num_pages = get_number_of_pages(page_soup)\n",
    "        original_publish_year = get_first_published(page_soup)\n",
    "        series = get_is_series(page_soup)\n",
    "        genres = get_genres(page_soup)\n",
    "        awards = get_awards(page_soup)\n",
    "        place = get_place(page_soup)\n",
    "        a_book = {\n",
    "            \"url\": [book_url],\n",
    "            \"title\":[title],\n",
    "            \"author\" :[author],\n",
    "            \"avg_rating\": [avg_rating],\n",
    "            \"num_reviews\" : [num_ratings],\n",
    "            \"num_ratings\" : [num_ratings],\n",
    "            \"num_pages\" : [num_pages],\n",
    "            \"original_publish_year\" : [original_publish_year],\n",
    "            \"series\" :[series],\n",
    "            \"genres\" : [genres],\n",
    "            \"awards\" : [awards],\n",
    "            \"place\" : [place]}\n",
    "        pd_data.append(a_book)\n",
    "    return pd_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
